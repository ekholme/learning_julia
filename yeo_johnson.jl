#some practice writing a YeoJohnson transformation
#see here https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation
#and here https://github.com/tk3369/YeoJohnsonTrans.jl

using Statistics
using Distributions
using Optim
using CairoMakie

a = collect(1:10)
b = collect(11:20)

#transform data given a vector x and Î»
function YJTransform(x, Î»)
    y = similar(x, Float64)
    for (i, v) in enumerate(x)
        if v >= 0
            y[i] = Î» â‰ˆ 0 ? log(v + 1) : ((v + 1)^Î» - 1) / Î»
        else
            y[i] = Î» â‰ˆ 2 ? -log(-v + 1) : -((-v + 1)^(2-Î»)-1) / (2-Î»)
        end
    end
    y
end


#calculate the log likelihood of the distribution/parameters given a vector x
function log_ll(x, Î»)
    ð± = YJTransform(x, Î»)

    Î¼ = mean(skipmissing(ð±))
    Ïƒ = std(skipmissing(ð±), corrected = false)

    d = Distributions.Normal(Î¼, Ïƒ)

    res = -loglikelihood(d, ð±)
    #the above is the same is -sum(logpdf.(d, x))
    return res
end

#estimate lambda for a given vector x
function lambda(x; interval=(-2.0, 2.0))
    i1, i2 = interval
    #see here for more on optimizing
    #https://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/#minimizing-a-univariate-function-on-a-bounded-interval
    res = optimize(Î» -> log_ll(x, Î»), i1, i2)
    Optim.minimizer(res)
end

#transform a vector just given lambda
function YJTransform(x)
    Î» = lambda(x)

    YJTransform(x, Î»)
end

#and let's test this out now
s = rand(LogNormal(), 1000)
tt = log.(s)

aa = YJTransform(s)

#so this isn't right
hist(aa)
hist(s)

#and let's see what value of lambda this gets us
lam = lambda(s)

#let's try with a normal distribution -- this should give us a lambda of 1
s_n = rand(Normal(), 10000)
mean(s_n)
std(s_n)

lam_sn = lambda(s_n)
#ok that's about right

#and then we can convert this
s_nâ€² = YJTransform(s_n)


